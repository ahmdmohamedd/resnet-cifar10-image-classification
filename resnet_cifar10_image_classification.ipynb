{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7d07d-d0dc-4e51-9079-db518aded012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a8472-6e50-48b1-a322-7eff79e1c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your downloaded CIFAR-10 dataset\n",
    "data_dir = r'C:\\Users\\ahmed\\Documents\\Python Scripts\\Image classification ResNet\\cifar-10-batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ed000-cabe-4227-990d-c8edd6eabc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle the dataset files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Load all training batches\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    batch_file = os.path.join(data_dir, f'data_batch_{i}')\n",
    "    batch = unpickle(batch_file)\n",
    "    train_data.append(batch[b'data'])\n",
    "    train_labels += batch[b'labels']\n",
    "\n",
    "# Convert training data to numpy arrays\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Load the test batch\n",
    "test_batch = unpickle(os.path.join(data_dir, 'test_batch'))\n",
    "test_data = test_batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "test_labels = np.array(test_batch[b'labels'])\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7749134-2b2b-4338-b4ba-0cbc61cef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert numpy array to PIL image for transformation\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b807e-3016-4c1a-b811-5411f1639bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Prepare the datasets\n",
    "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform)\n",
    "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform)\n",
    "\n",
    "# Load data into DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554306f2-9695-4a5e-8f5e-11e54ac67885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final one\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer with the number of classes in CIFAR-10\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc1bb8-04ad-4968-b592-7868540252ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15616cd9-e868-428a-a5bb-a95e7f2623b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_model(model, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluation mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Loop through the data\n",
    "            loader = train_loader if phase == 'train' else test_loader\n",
    "            for i, (inputs, labels) in enumerate(loader):\n",
    "                inputs = inputs.to(device)\n",
    "                \n",
    "                # Convert labels to LongTensor\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass and optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Track the loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                # Print loss and accuracy every 100 batches\n",
    "                if phase == 'train' and i % 100 == 0:\n",
    "                    print(f'Batch {i}/{len(loader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454148d-5247-40c4-8ac1-b52a3eb1fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60e822-ec4d-47d4-8244-c1fa37ef1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet18_cifar10.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
